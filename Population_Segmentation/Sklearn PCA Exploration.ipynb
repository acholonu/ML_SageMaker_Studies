{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit382pyenv430af317426d4b00b5bfb80853c722cd",
   "display_name": "Python 3.8.2 64-bit ('3.8.2': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The goal of this jupyter notebook is to understand what SageMaker really buys me.  Because SKlearn has a free version of all the algorithms that SageMaker provides.  So I am doing this experiment.  \n",
    "\n",
    "## Question trying to answer: \n",
    "\n",
    "1. Is SageMaker really about computing?  \n",
    "    - So if you have a model that you are trying to training.  If there are a lot of data, will it take to long on your personal computer?  If so, then you would use SageMaker.\n",
    "\n",
    "2. Is it about getting the results of your training?\n",
    "\n",
    "3.  Is it about the storage of model artifacts?\n",
    "    - SageMaker does the wrapper of results of SKlearn a little better.  You can still create the results how you want, but you would have to do this each time you ran a model.  So it would be nice to use the API on my local machine, but maybe store the results on S3. I don't think using the notebook instance is that valuable.\n",
    "\n",
    "4.  Is it the organization of model experiments and tracking experiments\n",
    "\n",
    "5.  Is about the ability to easily reload past model experiments and use it?\n",
    "\n",
    "6. I don't care about endpoints. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data managing and display libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Sklearn \n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             State  TotalPop       Men     Women  Hispanic     White  \\\n0  Alabama-Autauga  0.005475  0.005381  0.005566  0.026026  0.759519   \n1  Alabama-Baldwin  0.019411  0.019246  0.019572  0.045045  0.832665   \n2  Alabama-Barbour  0.002656  0.002904  0.002416  0.046046  0.462926   \n3     Alabama-Bibb  0.002225  0.002414  0.002042  0.022022  0.746493   \n4   Alabama-Blount  0.005722  0.005738  0.005707  0.086086  0.880762   \n\n      Black    Native     Asian  Pacific  ...      Walk  OtherTransp  \\\n0  0.215367  0.004343  0.024038      0.0  ...  0.007022     0.033248   \n1  0.110594  0.006515  0.016827      0.0  ...  0.014045     0.035806   \n2  0.543655  0.002172  0.009615      0.0  ...  0.025281     0.038363   \n3  0.249127  0.004343  0.002404      0.0  ...  0.008427     0.038363   \n4  0.017462  0.003257  0.002404      0.0  ...  0.012640     0.010230   \n\n   WorkAtHome  MeanCommute  Employed  PrivateWork  PublicWork  SelfEmployed  \\\n0    0.048387     0.552430  0.005139     0.750000    0.250000      0.150273   \n1    0.104839     0.549872  0.018507     0.884354    0.107616      0.158470   \n2    0.043011     0.491049  0.001819     0.719388    0.248344      0.199454   \n3    0.018817     0.611253  0.001754     0.804422    0.170530      0.183060   \n4    0.061828     0.767263  0.004751     0.892857    0.127483      0.114754   \n\n   FamilyWork  Unemployment  \n0    0.000000      0.208219  \n1    0.040816      0.205479  \n2    0.010204      0.482192  \n3    0.040816      0.227397  \n4    0.040816      0.210959  \n\n[5 rows x 35 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>TotalPop</th>\n      <th>Men</th>\n      <th>Women</th>\n      <th>Hispanic</th>\n      <th>White</th>\n      <th>Black</th>\n      <th>Native</th>\n      <th>Asian</th>\n      <th>Pacific</th>\n      <th>...</th>\n      <th>Walk</th>\n      <th>OtherTransp</th>\n      <th>WorkAtHome</th>\n      <th>MeanCommute</th>\n      <th>Employed</th>\n      <th>PrivateWork</th>\n      <th>PublicWork</th>\n      <th>SelfEmployed</th>\n      <th>FamilyWork</th>\n      <th>Unemployment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alabama-Autauga</td>\n      <td>0.005475</td>\n      <td>0.005381</td>\n      <td>0.005566</td>\n      <td>0.026026</td>\n      <td>0.759519</td>\n      <td>0.215367</td>\n      <td>0.004343</td>\n      <td>0.024038</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.007022</td>\n      <td>0.033248</td>\n      <td>0.048387</td>\n      <td>0.552430</td>\n      <td>0.005139</td>\n      <td>0.750000</td>\n      <td>0.250000</td>\n      <td>0.150273</td>\n      <td>0.000000</td>\n      <td>0.208219</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alabama-Baldwin</td>\n      <td>0.019411</td>\n      <td>0.019246</td>\n      <td>0.019572</td>\n      <td>0.045045</td>\n      <td>0.832665</td>\n      <td>0.110594</td>\n      <td>0.006515</td>\n      <td>0.016827</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.014045</td>\n      <td>0.035806</td>\n      <td>0.104839</td>\n      <td>0.549872</td>\n      <td>0.018507</td>\n      <td>0.884354</td>\n      <td>0.107616</td>\n      <td>0.158470</td>\n      <td>0.040816</td>\n      <td>0.205479</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alabama-Barbour</td>\n      <td>0.002656</td>\n      <td>0.002904</td>\n      <td>0.002416</td>\n      <td>0.046046</td>\n      <td>0.462926</td>\n      <td>0.543655</td>\n      <td>0.002172</td>\n      <td>0.009615</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.025281</td>\n      <td>0.038363</td>\n      <td>0.043011</td>\n      <td>0.491049</td>\n      <td>0.001819</td>\n      <td>0.719388</td>\n      <td>0.248344</td>\n      <td>0.199454</td>\n      <td>0.010204</td>\n      <td>0.482192</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alabama-Bibb</td>\n      <td>0.002225</td>\n      <td>0.002414</td>\n      <td>0.002042</td>\n      <td>0.022022</td>\n      <td>0.746493</td>\n      <td>0.249127</td>\n      <td>0.004343</td>\n      <td>0.002404</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.008427</td>\n      <td>0.038363</td>\n      <td>0.018817</td>\n      <td>0.611253</td>\n      <td>0.001754</td>\n      <td>0.804422</td>\n      <td>0.170530</td>\n      <td>0.183060</td>\n      <td>0.040816</td>\n      <td>0.227397</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Alabama-Blount</td>\n      <td>0.005722</td>\n      <td>0.005738</td>\n      <td>0.005707</td>\n      <td>0.086086</td>\n      <td>0.880762</td>\n      <td>0.017462</td>\n      <td>0.003257</td>\n      <td>0.002404</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.012640</td>\n      <td>0.010230</td>\n      <td>0.061828</td>\n      <td>0.767263</td>\n      <td>0.004751</td>\n      <td>0.892857</td>\n      <td>0.127483</td>\n      <td>0.114754</td>\n      <td>0.040816</td>\n      <td>0.210959</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 35 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Read in dataset\n",
    "df = pd.read_csv(\"counties_scaled.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                 TotalPop       Men     Women  Hispanic     White     Black  \\\nState                                                                         \nAlabama-Autauga  0.005475  0.005381  0.005566  0.026026  0.759519  0.215367   \nAlabama-Baldwin  0.019411  0.019246  0.019572  0.045045  0.832665  0.110594   \nAlabama-Barbour  0.002656  0.002904  0.002416  0.046046  0.462926  0.543655   \nAlabama-Bibb     0.002225  0.002414  0.002042  0.022022  0.746493  0.249127   \nAlabama-Blount   0.005722  0.005738  0.005707  0.086086  0.880762  0.017462   \n\n                   Native     Asian  Pacific   Citizen  ...      Walk  \\\nState                                                   ...             \nAlabama-Autauga  0.004343  0.024038      0.0  0.006702  ...  0.007022   \nAlabama-Baldwin  0.006515  0.016827      0.0  0.024393  ...  0.014045   \nAlabama-Barbour  0.002172  0.009615      0.0  0.003393  ...  0.025281   \nAlabama-Bibb     0.004343  0.002404      0.0  0.002860  ...  0.008427   \nAlabama-Blount   0.003257  0.002404      0.0  0.006970  ...  0.012640   \n\n                 OtherTransp  WorkAtHome  MeanCommute  Employed  PrivateWork  \\\nState                                                                          \nAlabama-Autauga     0.033248    0.048387     0.552430  0.005139     0.750000   \nAlabama-Baldwin     0.035806    0.104839     0.549872  0.018507     0.884354   \nAlabama-Barbour     0.038363    0.043011     0.491049  0.001819     0.719388   \nAlabama-Bibb        0.038363    0.018817     0.611253  0.001754     0.804422   \nAlabama-Blount      0.010230    0.061828     0.767263  0.004751     0.892857   \n\n                 PublicWork  SelfEmployed  FamilyWork  Unemployment  \nState                                                                \nAlabama-Autauga    0.250000      0.150273    0.000000      0.208219  \nAlabama-Baldwin    0.107616      0.158470    0.040816      0.205479  \nAlabama-Barbour    0.248344      0.199454    0.010204      0.482192  \nAlabama-Bibb       0.170530      0.183060    0.040816      0.227397  \nAlabama-Blount     0.127483      0.114754    0.040816      0.210959  \n\n[5 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TotalPop</th>\n      <th>Men</th>\n      <th>Women</th>\n      <th>Hispanic</th>\n      <th>White</th>\n      <th>Black</th>\n      <th>Native</th>\n      <th>Asian</th>\n      <th>Pacific</th>\n      <th>Citizen</th>\n      <th>...</th>\n      <th>Walk</th>\n      <th>OtherTransp</th>\n      <th>WorkAtHome</th>\n      <th>MeanCommute</th>\n      <th>Employed</th>\n      <th>PrivateWork</th>\n      <th>PublicWork</th>\n      <th>SelfEmployed</th>\n      <th>FamilyWork</th>\n      <th>Unemployment</th>\n    </tr>\n    <tr>\n      <th>State</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Alabama-Autauga</th>\n      <td>0.005475</td>\n      <td>0.005381</td>\n      <td>0.005566</td>\n      <td>0.026026</td>\n      <td>0.759519</td>\n      <td>0.215367</td>\n      <td>0.004343</td>\n      <td>0.024038</td>\n      <td>0.0</td>\n      <td>0.006702</td>\n      <td>...</td>\n      <td>0.007022</td>\n      <td>0.033248</td>\n      <td>0.048387</td>\n      <td>0.552430</td>\n      <td>0.005139</td>\n      <td>0.750000</td>\n      <td>0.250000</td>\n      <td>0.150273</td>\n      <td>0.000000</td>\n      <td>0.208219</td>\n    </tr>\n    <tr>\n      <th>Alabama-Baldwin</th>\n      <td>0.019411</td>\n      <td>0.019246</td>\n      <td>0.019572</td>\n      <td>0.045045</td>\n      <td>0.832665</td>\n      <td>0.110594</td>\n      <td>0.006515</td>\n      <td>0.016827</td>\n      <td>0.0</td>\n      <td>0.024393</td>\n      <td>...</td>\n      <td>0.014045</td>\n      <td>0.035806</td>\n      <td>0.104839</td>\n      <td>0.549872</td>\n      <td>0.018507</td>\n      <td>0.884354</td>\n      <td>0.107616</td>\n      <td>0.158470</td>\n      <td>0.040816</td>\n      <td>0.205479</td>\n    </tr>\n    <tr>\n      <th>Alabama-Barbour</th>\n      <td>0.002656</td>\n      <td>0.002904</td>\n      <td>0.002416</td>\n      <td>0.046046</td>\n      <td>0.462926</td>\n      <td>0.543655</td>\n      <td>0.002172</td>\n      <td>0.009615</td>\n      <td>0.0</td>\n      <td>0.003393</td>\n      <td>...</td>\n      <td>0.025281</td>\n      <td>0.038363</td>\n      <td>0.043011</td>\n      <td>0.491049</td>\n      <td>0.001819</td>\n      <td>0.719388</td>\n      <td>0.248344</td>\n      <td>0.199454</td>\n      <td>0.010204</td>\n      <td>0.482192</td>\n    </tr>\n    <tr>\n      <th>Alabama-Bibb</th>\n      <td>0.002225</td>\n      <td>0.002414</td>\n      <td>0.002042</td>\n      <td>0.022022</td>\n      <td>0.746493</td>\n      <td>0.249127</td>\n      <td>0.004343</td>\n      <td>0.002404</td>\n      <td>0.0</td>\n      <td>0.002860</td>\n      <td>...</td>\n      <td>0.008427</td>\n      <td>0.038363</td>\n      <td>0.018817</td>\n      <td>0.611253</td>\n      <td>0.001754</td>\n      <td>0.804422</td>\n      <td>0.170530</td>\n      <td>0.183060</td>\n      <td>0.040816</td>\n      <td>0.227397</td>\n    </tr>\n    <tr>\n      <th>Alabama-Blount</th>\n      <td>0.005722</td>\n      <td>0.005738</td>\n      <td>0.005707</td>\n      <td>0.086086</td>\n      <td>0.880762</td>\n      <td>0.017462</td>\n      <td>0.003257</td>\n      <td>0.002404</td>\n      <td>0.0</td>\n      <td>0.006970</td>\n      <td>...</td>\n      <td>0.012640</td>\n      <td>0.010230</td>\n      <td>0.061828</td>\n      <td>0.767263</td>\n      <td>0.004751</td>\n      <td>0.892857</td>\n      <td>0.127483</td>\n      <td>0.114754</td>\n      <td>0.040816</td>\n      <td>0.210959</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 34 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df.index = df['State']\n",
    "df.drop(columns='State',inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use PCA it has to be a numpy array\n",
    "train_data_np = df.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMPONENTS = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the algorithm (hyperparameters)\n",
    "pca = PCA(n_components=N_COMPONENTS, svd_solver='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PCA(n_components=33, svd_solver='full')"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# It was fast.  Less than 1 secs\n",
    "# the instance now stores all single-value decompositions values, dataset descriptors\n",
    "# explained-variance\n",
    "pca.fit(train_data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "PCA is doing Single Value Decomposition\n",
    "\n",
    "**SVD=UÎ£VT**\n",
    "T= transpose, so V_transpose\n",
    "\n",
    "U how each subject (e.g., counties in this example) relates to the latent factors (the moved and translated dimensions)\n",
    "V_transpose relates to how the columns (e.g., measurement types) relate to the latent factors.\n",
    "Sigma is a k x k diagonal matrix.  It helps us decide how many factors to keeps.  (showing the how each fitted dimensions explain the variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Model Attributes\n",
    "\n",
    "Three types of model attributes are contained within the PCA model.\n",
    "\n",
    "* **mean**: The mean that was subtracted from a component in order to center it.\n",
    "* **v**: The makeup of the principal components; (same as â€˜components_â€™ in an sklearn PCA model).\n",
    "* **s**: The singular values of the components for the PCA transformation. This does not exactly give the % variance from the original feature space, but can give the % variance from the projected feature space.\n",
    "    \n",
    "We are only interested in v and s. \n",
    "\n",
    "From s, we can get an approximation of the data variance that is covered in the first `n` principal components. The approximate explained variance is given by the formula: the sum of squared s values for all top n components over the sum over squared s values for _all_ components:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\sum_{n}^{ } s_n^2}{\\sum s^2}\n",
    "\\end{equation*}\n",
    "\n",
    "From v, we can learn more about the combi\n",
    "nations of original features that make up each principal component.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     3.209868e-01\n1     1.421049e-01\n2     1.148278e-01\n3     8.666071e-02\n4     5.340210e-02\n5     4.951809e-02\n6     3.417160e-02\n7     2.991340e-02\n8     2.602435e-02\n9     2.106444e-02\n10    1.724376e-02\n11    1.579245e-02\n12    1.467393e-02\n13    1.142748e-02\n14    1.067634e-02\n15    9.639916e-03\n16    7.614509e-03\n17    6.587862e-03\n18    6.075651e-03\n19    4.759028e-03\n20    4.410688e-03\n21    3.924108e-03\n22    2.644663e-03\n23    2.129502e-03\n24    1.906785e-03\n25    1.658913e-03\n26    1.357431e-04\n27    1.348715e-05\n28    7.520258e-06\n29    1.057873e-06\n30    9.965286e-07\n31    7.975693e-07\n32    6.142346e-07\ndtype: float32"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "explained_var = pd.Series(pca.explained_variance_ratio_)\n",
    "explained_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.80167204"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "explained_var[:7].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in general, you want your models to capture at least 80% of the variance. So, in this case, I would keep at least the top 7 dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[19.592176   13.035978   11.718245   10.180057    7.991315    7.6952195\n  6.392515    5.980974    5.578649    5.018963    4.5410376   4.3457413\n  4.1890187   3.6967015   3.5731425   3.3952808   3.0175886   2.806799\n  2.695476    2.3856032   2.2966366   2.1662548   1.7783786   1.5957989\n  1.510045    1.4084805   0.4029007   0.12699868  0.09483211  0.0355677\n  0.03452105  0.03088327  0.0271023 ]\n"
    }
   ],
   "source": [
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 5.04592387e-03  4.95318510e-03  5.13611455e-03 ... -6.34508505e-02\n  -1.42857628e-02  2.33626753e-01]\n [-1.59877054e-02 -1.57302711e-02 -1.62377879e-02 ...  3.09405625e-01\n   7.06733987e-02 -1.20168991e-01]\n [ 7.63924643e-02  7.59586319e-02  7.68135563e-02 ... -1.39890611e-01\n  -4.17343006e-02 -6.97059631e-02]\n ...\n [ 1.17335969e-03 -9.72318370e-03  1.17554124e-02 ... -3.72649968e-01\n  -9.91007686e-02 -7.19352538e-05]\n [-2.53616087e-02  6.83546364e-01 -7.13751435e-01 ...  2.52577569e-03\n   7.08975422e-04 -2.98635248e-04]\n [ 4.76849731e-03 -7.12749660e-02  7.86113143e-02 ... -1.14719095e-02\n  -2.81052268e-03  8.26647738e-05]]\n"
    }
   ],
   "source": [
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.DataFrame(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         0         1         2         3         4         5         6   \\\n0  0.005046  0.004953  0.005136  0.392619 -0.601972  0.207530  0.038430   \n1 -0.015988 -0.015730 -0.016238  0.278089 -0.092913 -0.348800  0.113913   \n2  0.076392  0.075959  0.076814  0.322116 -0.373134  0.001155 -0.038152   \n3  0.009003  0.008634  0.009362 -0.534676 -0.160297  0.622484  0.124463   \n4 -0.016843 -0.016702 -0.016979  0.102067 -0.210338  0.307640 -0.136468   \n\n         7         8         9   ...        24        25        26        27  \\\n0 -0.004536  0.001652  0.004569  ... -0.004034  0.013728 -0.078116  0.054965   \n1  0.002378  0.014045 -0.019234  ...  0.120834  0.039226  0.225706 -0.288411   \n2  0.173815  0.018965  0.084550  ... -0.014532  0.012386 -0.009739  0.120439   \n3  0.059567  0.011659  0.011346  ...  0.063648  0.042423  0.088901 -0.064774   \n4 -0.026954 -0.003319 -0.022274  ... -0.046131 -0.033763  0.012945  0.306704   \n\n         28        29        30        31        32        33  \n0  0.003422 -0.103600  0.141609 -0.063451 -0.014286  0.233627  \n1 -0.015866 -0.443172  0.232524  0.309406  0.070673 -0.120169  \n2  0.079684  0.182157 -0.085712 -0.139891 -0.041734 -0.069706  \n3  0.010629 -0.259197  0.243868  0.009620  0.015787  0.031820  \n4 -0.016639  0.069203 -0.138455  0.112136  0.019906 -0.142847  \n\n[5 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n      <th>31</th>\n      <th>32</th>\n      <th>33</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.005046</td>\n      <td>0.004953</td>\n      <td>0.005136</td>\n      <td>0.392619</td>\n      <td>-0.601972</td>\n      <td>0.207530</td>\n      <td>0.038430</td>\n      <td>-0.004536</td>\n      <td>0.001652</td>\n      <td>0.004569</td>\n      <td>...</td>\n      <td>-0.004034</td>\n      <td>0.013728</td>\n      <td>-0.078116</td>\n      <td>0.054965</td>\n      <td>0.003422</td>\n      <td>-0.103600</td>\n      <td>0.141609</td>\n      <td>-0.063451</td>\n      <td>-0.014286</td>\n      <td>0.233627</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.015988</td>\n      <td>-0.015730</td>\n      <td>-0.016238</td>\n      <td>0.278089</td>\n      <td>-0.092913</td>\n      <td>-0.348800</td>\n      <td>0.113913</td>\n      <td>0.002378</td>\n      <td>0.014045</td>\n      <td>-0.019234</td>\n      <td>...</td>\n      <td>0.120834</td>\n      <td>0.039226</td>\n      <td>0.225706</td>\n      <td>-0.288411</td>\n      <td>-0.015866</td>\n      <td>-0.443172</td>\n      <td>0.232524</td>\n      <td>0.309406</td>\n      <td>0.070673</td>\n      <td>-0.120169</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.076392</td>\n      <td>0.075959</td>\n      <td>0.076814</td>\n      <td>0.322116</td>\n      <td>-0.373134</td>\n      <td>0.001155</td>\n      <td>-0.038152</td>\n      <td>0.173815</td>\n      <td>0.018965</td>\n      <td>0.084550</td>\n      <td>...</td>\n      <td>-0.014532</td>\n      <td>0.012386</td>\n      <td>-0.009739</td>\n      <td>0.120439</td>\n      <td>0.079684</td>\n      <td>0.182157</td>\n      <td>-0.085712</td>\n      <td>-0.139891</td>\n      <td>-0.041734</td>\n      <td>-0.069706</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.009003</td>\n      <td>0.008634</td>\n      <td>0.009362</td>\n      <td>-0.534676</td>\n      <td>-0.160297</td>\n      <td>0.622484</td>\n      <td>0.124463</td>\n      <td>0.059567</td>\n      <td>0.011659</td>\n      <td>0.011346</td>\n      <td>...</td>\n      <td>0.063648</td>\n      <td>0.042423</td>\n      <td>0.088901</td>\n      <td>-0.064774</td>\n      <td>0.010629</td>\n      <td>-0.259197</td>\n      <td>0.243868</td>\n      <td>0.009620</td>\n      <td>0.015787</td>\n      <td>0.031820</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.016843</td>\n      <td>-0.016702</td>\n      <td>-0.016979</td>\n      <td>0.102067</td>\n      <td>-0.210338</td>\n      <td>0.307640</td>\n      <td>-0.136468</td>\n      <td>-0.026954</td>\n      <td>-0.003319</td>\n      <td>-0.022274</td>\n      <td>...</td>\n      <td>-0.046131</td>\n      <td>-0.033763</td>\n      <td>0.012945</td>\n      <td>0.306704</td>\n      <td>-0.016639</td>\n      <td>0.069203</td>\n      <td>-0.138455</td>\n      <td>0.112136</td>\n      <td>0.019906</td>\n      <td>-0.142847</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 34 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(33, 34)"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "#rows = princpal components\n",
    "#col = features (x inputs)\n",
    "# so I need to transpose this panda to get it in the form I like (components x features)\n",
    "# Need to double check the order of principal components and features after I do this transpose\n",
    "# This is something I wouldn't necessary have to do with SageMaker sdk\n",
    "# Would love to run SageMaker locally\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The singular_values are the diagnols of Sigma (which is a square matrix with 0's outside of the diagnols)\n",
    "results ={\n",
    "    'explain_var_percent' : pca.explained_variance_ratio_,\n",
    "    'singular_values' : pca.singular_values_, # this is s: and tells you more about the variance explained\n",
    "    'principal_components' : pca.components_ # This is v_transposed:\n",
    "}"
   ]
  }
 ]
}